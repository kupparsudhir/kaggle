{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "11a77013-2090-4bd9-9906-43f157016666",
        "_uuid": "34e7b6765b958cf25a7c2ccbf73a41e0f80ddd39"
      },
      "cell_type": "markdown",
      "source": "# Import library"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "e6cfe7c7-f6e4-41c1-bc88-f3e4f47f3dd8",
        "_uuid": "24dba3003f223b6750fc78c5dc99f7d58cfd5c01",
        "trusted": false
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import word_tokenize\nimport string\n\nfrom sklearn.model_selection import train_test_split,KFold\nfrom sklearn.metrics import confusion_matrix,roc_auc_score,log_loss\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n#import xgboost as xgb \nseed = 4353",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "1d733158-570d-418e-83d6-07343565c90c",
        "_uuid": "9b1e3160abe7cdf7ac2260624f48c8047e092f41"
      },
      "cell_type": "markdown",
      "source": "# Load data set"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "dd530fd2-666b-4b1b-b9f5-4efde11c2581",
        "_uuid": "dd7d9b470f136f4e59a466c710af9333a8ed9691",
        "trusted": false
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3116921b-aa3c-4bd3-866d-1edba01ef27c",
        "_uuid": "2e1ba7ac2c5105852a95c0f2118fe77400458903"
      },
      "cell_type": "markdown",
      "source": "# Explore data set"
    },
    {
      "metadata": {
        "_cell_guid": "68faba26-6239-44f1-b2e5-34b133139eb5",
        "_uuid": "4bdff4427d34a04cf04a0ccce26aa9378347cb08",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('Number of rows and columns in data set',train.shape)\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "8e39de29-c064-495b-a66a-94ed6f107c63",
        "_uuid": "457f943d0e8ab8496007844728c118544c6371bd",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('Number of rows and columns in data set',test.shape)\ntest.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "88a2980b-7ced-4390-b658-ccf03c6acf01",
        "_uuid": "6fc76674c645839d451512301581bb8886e75ac8"
      },
      "cell_type": "markdown",
      "source": "# Authors Target variable distribution"
    },
    {
      "metadata": {
        "_cell_guid": "6a9f634f-a99a-47a9-9155-a1808ba17c61",
        "_uuid": "0fb44df7fdafaa0f2cdd21c41da6a62f752b9cfb",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train['author'].value_counts()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "f93d547f-334c-4d0d-a612-40266317556d",
        "_uuid": "e9afa4961e03d8f1e55a66561e3b8f645e4cae13",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(14,5))\nsns.countplot(train['author'],)\nplt.xlabel('Author')\nplt.title('Target variable distribution')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "145ca7eb-a147-4e49-9b0f-350d5862c50c",
        "_uuid": "104fe0627296da12a92d8dcaa8c3abdb47657ece"
      },
      "cell_type": "markdown",
      "source": "# Text cleaning"
    },
    {
      "metadata": {
        "_cell_guid": "b9585dc2-4846-480f-9f47-6cc541201939",
        "_uuid": "770cb0c7e7012c7beb2c607fef08c0945d7b79e2"
      },
      "cell_type": "markdown",
      "source": "## Remove unwanted punctuation mark"
    },
    {
      "metadata": {
        "_cell_guid": "412ef883-fb27-4c00-81d1-8cee22506a77",
        "_uuid": "d8dd3b37b46a6ab23796ae49958f0fccb8991d6e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "print('Original text:\\n',train['text'][0])\nreview = re.sub('[^A-Za-z0-9]',\" \",train['text'][0]) \nprint('\\nAfter removal of punctuation:\\n',review)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "759881e4-feec-4584-96b5-1b3b167fed03",
        "_uuid": "06b77311530c749cd7009d6cd2bbfd7daf081eb4"
      },
      "cell_type": "markdown",
      "source": "# Split sentence into word"
    },
    {
      "metadata": {
        "_cell_guid": "c36e236d-c6a3-4d40-a86d-9de9f04b1882",
        "_uuid": "27233d5b661108e120e8d1326d5d2e5f7f00efa9",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "review = word_tokenize(train['text'][0]) \nprint('Word Tokenize:\\n',review)\n\nreview = [word for word in str(train['text'][0]).lower().split() if  word not in set(stopwords.words('english'))]\nprint('\\nRemoval of Stopwords:\\n',review)\n\nreview = [word for word in str(train['text'][0]).lower().split() if  word in set(stopwords.words('english'))]\nprint('\\nStopwords in the sentence:\\n',review)\n\nps = PorterStemmer()\nreview = [ps.stem(word) for word in str(train['text'][0]).lower().split()]\nprint('\\nStemming of word:\\n',review)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "64c5c526-6d45-4a57-8122-22556bb3092c",
        "_uuid": "58b8915feac6ef56c64318b997c11321eab7df10"
      },
      "cell_type": "markdown",
      "source": "# Function for text cleaning"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "d64ce283-d65b-4da3-8934-a5fe1504cf3e",
        "_uuid": "c8dc1bce457e7c3ae7bc37fe71501966bbd61069",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def clean_text(df):\n    ps = PorterStemmer()\n    corpus = []\n    for i in range(0, df.shape[0]):        \n        review = re.sub('[^A-Za-z0-9]',\" \",df['text'][i])\n        review = word_tokenize(review)        \n        review = [word for word in review if word.lower() not in set(stopwords.words('english'))]\n        review = [ps.stem(word) for word in review]\n        review = ' '.join(review)\n        corpus.append(review)\n    \n    return corpus",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "6dcd8cb6-5908-4700-be63-942e559bfab2",
        "_uuid": "8d3932505d8e450a572c01865b1ef1157fd3e895",
        "trusted": false
      },
      "cell_type": "code",
      "source": "corp_train = clean_text(train)\ncorp_test = clean_text(test)\ntrain['clean_text'] = corp_train\ntest['clean_text'] = corp_test\ndel corp_train,corp_test",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "24d07075-9a9c-4adb-9192-3433ba8a3f7f",
        "_uuid": "367b10f4e6ba1175f45124d1f7b076dcea4294fa"
      },
      "cell_type": "markdown",
      "source": "# Determine length of text"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "e8425d32-c3f0-4b7a-910d-a001d9d6850f",
        "_uuid": "461f7ca4dfac7e281cc2f3b79efdcf6e456a0a3d",
        "trusted": false
      },
      "cell_type": "code",
      "source": "def text_len(df):\n    #i = ['text']\n    df['num_words'] = df['text'].apply(lambda x: len(str(x).split()))\n    df['num_uniq_words'] = df['text'].apply(lambda x: len(set(str(x).split())))\n    df['num_chars'] = df['text'].apply(lambda x: len(str(x)))\n    df['num_stopwords'] = df['text'].apply(lambda x: len([w for w in str(x).lower().split() \n                                                          if w in set(stopwords.words('english'))]))\n    df['num_punctuations'] = df['text'].apply(lambda x: len([w for w in str(x) if w in string.punctuation]))\n    df['num_words_upper'] = df['text'].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n    df['num_words_title'] = df['text'].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n    df['mean_word_len'] = df['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n\ntext_len(train)\ntext_len(test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ea54a41e-d1e8-4780-a2df-2d983e71a0e1",
        "_uuid": "8f9125ad4065185bcd2a0f57145fbdd91db5476e"
      },
      "cell_type": "markdown",
      "source": "# Data analysis"
    },
    {
      "metadata": {
        "_cell_guid": "147e722a-67b6-4e2f-bfb3-6b2a06faa89f",
        "_uuid": "2fa287fcce5cdbbf460982e179709e89adc9fa28",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(14,6))\nplt.subplot(211)\nsns.heatmap(pd.crosstab(train['author'],train['num_words']),cmap='gist_earth',xticklabels=False)\nplt.xlabel('Original text word count')\nplt.ylabel('Author')\n\nplt.subplot(212)\nsns.heatmap(pd.crosstab(train['author'],train['num_uniq_words']),cmap='gist_heat',xticklabels=False)\nplt.xlabel('Unique text word count')\nplt.ylabel('Author')\nplt.tight_layout()\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ccf90800-13d9-4a11-8faf-3e46fe8c650d",
        "_uuid": "45a676ac052a039e0b914fb6e831e3a3ddd2a798",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(14,6))\nsns.distplot(train['num_words'],bins=100,color='r')\nplt.title('Distribution of original text words')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "baa01aa3-a561-42d9-a284-90740d28dbdd",
        "_uuid": "33ba042b3b0bb4674fcaa61d1b5e908ce8d47448",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train['num_uniq_words'].value_counts()[0:10].plot(kind='bar',color=['r','b'])\nplt.xlabel('Original text word count')\nplt.ylabel('Count')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b91533aa-d32c-43db-bfa9-515cfee97cea",
        "_uuid": "96acb851f11a5fdab134a97cf8267faddf8808b4",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(14,6))\nsns.heatmap(train.corr(),annot=True)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b8d6db4c-8342-4f5d-920b-7afcb0518ff9",
        "_uuid": "540fdae07bbe31d28709228e4e9db2c71df80506"
      },
      "cell_type": "markdown",
      "source": "# Bag of words"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "e7338fa7-e804-4df7-853a-13e4c63d87ce",
        "_uuid": "e1038c7a3ca63fc90ccad559bdef19e0b2851243",
        "trusted": false
      },
      "cell_type": "code",
      "source": "cv =CountVectorizer(max_features=5000,ngram_range=(1,3),dtype=np.int8,stop_words='english')\nX_cv = cv.fit_transform(train['clean_text']).toarray()\nX_test_cv = cv.fit_transform(test['clean_text']).toarray()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ee54a322-6ad0-4ba7-842a-09c036aaf547",
        "_uuid": "3db054239780aa8ec608bdfff06d8b2ac3d4b188"
      },
      "cell_type": "markdown",
      "source": "# Encoder"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "c9d57909-9c15-48df-a728-72151d2edcc0",
        "_uuid": "3d1a1e64abc64875a56215559164734ce8b53fb3",
        "trusted": false
      },
      "cell_type": "code",
      "source": "author_name = {'EAP':0,'HPL':1,'MWS':2}\ny = train['author'].map(author_name) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b9607c88-ff1c-4d33-9eb4-b470dff76b97",
        "_uuid": "dbba4da5cbce1d5a79d4d84303c0fec9978df51e"
      },
      "cell_type": "markdown",
      "source": "# Naive Bayes classifier"
    },
    {
      "metadata": {
        "_cell_guid": "28ba0016-5d1e-4d67-8de5-3ed2bdfdadb1",
        "_uuid": "704e07cc3754fea1e2c4121c8b553fe7e1e9ce1d",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "mNB = MultinomialNB()\n\nkf = KFold(n_splits=10,shuffle=True,random_state=seed)\npred_test_full = 0\ncv_score = []\ni=1\nfor train_index,test_index in kf.split(X_cv):\n    print('{} of KFlod {}'.format(i,kf.n_splits))    \n    xtr,xvl = X_cv[train_index], X_cv[test_index]\n    ytr,yvl = y[train_index], y[test_index]\n    \n    mNB.fit(xtr,ytr)\n    y_mNB = mNB.predict(xvl)\n    cv_score.append(log_loss(yvl,mNB.predict_proba(xvl)))\n    print('confusion matrix:\\n',confusion_matrix(yvl,y_mNB))\n    pred_test_full += mNB.predict_proba(X_test_cv)\n    i+=1\n#roc_auc_score(yvl,mNB.predict_proba(xvl)[:,1]) # not for multi class\nprint(cv_score)\nprint('Mean accuracy score',np.mean(cv_score))\ndel xtr,ytr,xvl,yvl",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "3543f2e5-7799-483d-b4b0-30bb432f8944",
        "_uuid": "f35e477363a18f9c02141a59046f304cead2f243"
      },
      "cell_type": "markdown",
      "source": "#  Submit prediction for unseen dataset"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "85974d90-18d1-4c7c-bb1f-0b4c87f416ac",
        "_uuid": "d6f3b5b3e40d796b832115a916543c7388eb1964",
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = pred_test_full/10\nsubmit = pd.DataFrame(test['id'])\nsubmit = submit.join(pd.DataFrame(y_pred))\nsubmit.columns = ['id','EAP','HPL','MWS'] \n#submit.to_csv('spooky_pred1.csv.gz',index=False,compression='gzip')\nsubmit.to_csv('spooky_pred1.csv',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e59d5951-5e40-4cf1-84c5-c32ddb60b260",
        "_uuid": "dade6178146b564821dd30b066b8d65a83d574ce"
      },
      "cell_type": "markdown",
      "source": "# TfIdf  (Term frequency Inverse document frequency)"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "63f44ef1-5310-4f3e-b164-1c1248124299",
        "_uuid": "097f9573d2d30a46f1da24f8c20a24b9aa19140e",
        "trusted": false
      },
      "cell_type": "code",
      "source": "tfidf = TfidfVectorizer(max_features=5000,dtype=np.float32,analyzer='word',\n                        ngram_range=(1, 3),use_idf=True, smooth_idf=True, \n                        sublinear_tf=True,stop_words='english',tokenizer=word_tokenize)\nX_tf = tfidf.fit_transform(train['clean_text']).toarray()\nX_test_tf = tfidf.fit_transform(test['clean_text']).toarray()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "75dd821c-1615-4f9a-aca1-97f81414b0a3",
        "_uuid": "6373ecde7c0b52dd614324a58d15ac60bcc1bae8"
      },
      "cell_type": "markdown",
      "source": "# Naive Bayes classifier"
    },
    {
      "metadata": {
        "_cell_guid": "a4f9c724-3737-4c66-b23f-bac7625b5f79",
        "_uuid": "0b15e8e163755f35753a4f73a0baba920970a70e",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "mNB = MultinomialNB()\n\nkf = KFold(n_splits=10,shuffle=True,random_state=seed)\npred_test_full = 0\ncv_score = []\ni=1\nfor train_index,test_index in kf.split(X_tf):\n    print('{} of KFlod {}'.format(i,kf.n_splits))    \n    xtr,xvl = X_tf[train_index], X_tf[test_index]\n    ytr,yvl = y[train_index], y[test_index]\n    \n    mNB.fit(xtr,ytr)\n    y_mNB = mNB.predict(xvl)\n    cv_score.append(log_loss(yvl,mNB.predict_proba(xvl)))\n    print('confusion matrix:\\n',confusion_matrix(yvl,y_mNB))\n    pred_test_full += mNB.predict_proba(X_test_tf)\n    i+=1\n#roc_auc_score(yvl,mNB.predict_proba(xvl)[:,1]) # not for multi class\nprint(cv_score)\nprint('Mean accuracy score',np.mean(cv_score))\ndel xtr,ytr,xvl,yvl,X_tf,X_test_tf",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5337eb19-b85b-4cac-861e-f58dd3ae46fb",
        "_uuid": "dcd2f5d21982a845c8932583a8b87e5d6fe7b45f"
      },
      "cell_type": "markdown",
      "source": "#  Submit prediction for unseen dataset"
    },
    {
      "metadata": {
        "collapsed": true,
        "_cell_guid": "7b6d7355-a7c8-4651-9e8c-540d172d21ae",
        "_uuid": "b9db29c22cd096c15a79035830059600d4914838",
        "trusted": false
      },
      "cell_type": "code",
      "source": "y_pred = pred_test_full/10\nsubmit = pd.DataFrame(test['id'])\nsubmit = submit.join(pd.DataFrame(y_pred))\nsubmit.columns = ['id','EAP','HPL','MWS'] \n#submit.to_csv('spooky_pred2.csv.gz',index=False,compression='gzip')\nsubmit.to_csv('spooky_pred2.csv',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "0cb204f2-7cb7-4703-b200-d159ab501447",
        "_uuid": "be772e5daed67ca05458a167bd2fbb3b508933c0"
      },
      "cell_type": "markdown",
      "source": "Thank you for visiting"
    }
  ],
  "metadata": {
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.6.3",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}